{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensor Operations Practice - 20 Questions\n",
    "\n",
    "This notebook contains 20 challenging tensor operation questions focusing on slicing, reshaping, and n-dimensional tensor manipulations. Each question provides a straightforward task but requires careful understanding of tensor operations.\n",
    "\n",
    "**Instructions:**\n",
    "1. Read each question carefully\n",
    "2. Write your solution in the provided cell\n",
    "3. Run the test to verify your answer\n",
    "4. Expected output is provided for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/t1/nxkxh_9x0mlbzst9s7g14zrm0000gp/T/ipykernel_11421/2328415981.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/amanr/miniconda/envs/ai2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Advanced Slicing\n",
    "\n",
    "Create a random tensor of shape (8, 6, 4). Extract every 2nd element along dimension 0, every 3rd element along dimension 1, and reverse dimension 2.\n",
    "\n",
    "**Expected output shape:** (4, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([8, 6, 4])\n",
      "Result shape: torch.Size([4, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "x = torch.randn(8, 6, 4)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "\n",
    "result = x[::2, ::3, :]\n",
    "result = torch.flip(result, dims=[-1])\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (4, 2, 4), f\"Expected shape (4, 2, 4), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Complex Reshape and Transpose\n",
    "\n",
    "Create a tensor of shape (12, 8). Reshape it to (3, 4, 2, 4), then transpose dimensions 1 and 3.\n",
    "\n",
    "**Expected output shape:** (3, 4, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([12, 8])\n",
      "Result shape: torch.Size([3, 4, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "x = torch.randn(12, 8)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = torch.reshape(x, (3, 4, 2, 4))\n",
    "result = torch.transpose(result, 1, 3)\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (3, 4, 2, 4), f\"Expected shape (3, 4, 2, 4), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Diagonal Extraction\n",
    "\n",
    "Create a tensor of shape (5, 5, 3). Extract the diagonal elements from the first two dimensions for each of the 3 channels.\n",
    "\n",
    "**Expected output shape:** (5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([5, 5, 3])\n",
      "Result shape: torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "x = torch.randn(5, 5, 3)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = torch.diagonal(x, offset=0, dim1=0, dim2=1).transpose(0, 1)\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (5, 3), f\"Expected shape (5, 3), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Advanced Indexing with Boolean Mask\n",
    "\n",
    "Create a tensor of shape (6, 4). Create a boolean mask where elements are greater than 0. Use this mask to extract positive elements and reshape them into a 2D tensor with 2 columns (padding with zeros if necessary).\n",
    "\n",
    "**Hint:** You'll need to handle the variable number of positive elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([6, 4])\n",
      "Original tensor:\n",
      "tensor([[-1.3283, -1.2493, -0.1002,  1.2510],\n",
      "        [-0.1099, -1.4055,  0.1565,  0.4783],\n",
      "        [-0.7410, -0.8435,  1.5077,  0.1040],\n",
      "        [-0.5524,  0.3411,  0.5628, -0.2523],\n",
      "        [-1.4110, -0.2567, -0.1132,  0.0081],\n",
      "        [ 0.5133,  1.6130,  1.5870,  0.1421]])\n",
      "Result shape: torch.Size([6, 2])\n",
      "Result:\n",
      "tensor([[1.2510, 0.1565],\n",
      "        [0.4783, 1.5077],\n",
      "        [0.1040, 0.3411],\n",
      "        [0.5628, 0.0081],\n",
      "        [0.5133, 1.6130],\n",
      "        [1.5870, 0.1421]])\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "x = torch.randn(6, 4)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Original tensor:\\n{x}\")\n",
    "\n",
    "result = torch.masked_select(x, x > 0)\n",
    "# result = torch.reshape(result, (4, 2))\n",
    "result_count = result.numel()\n",
    "if result_count % 2 == 0:\n",
    "    result = result.reshape(-1, 2)\n",
    "else:\n",
    "    pad_size = 2 - (result_count % 2)\n",
    "    result = torch.cat((result, torch.zeros(pad_size, dtype=result.dtype)), dim=0)\n",
    "    result = result.reshape(-1, 2)\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Result:\\n{result}\")\n",
    "assert result.shape[1] == 2, f\"Expected 2 columns, got {result.shape[1]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Tensor Unfolding\n",
    "\n",
    "Create a tensor of shape (1, 1, 8, 8). Use `torch.nn.functional.unfold` to extract 3x3 patches with stride 2.\n",
    "\n",
    "**Expected output shape:** (1, 9, 9) - 9 values per patch, 9 patches total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.randn(1, 1, 8, 8)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (1, 9, 9), f\"Expected shape (1, 9, 9), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Multi-dimensional Indexing\n",
    "\n",
    "Create a tensor of shape (4, 5, 6). Use advanced indexing to select:\n",
    "- Elements at positions (0,1,2), (1,2,3), (2,3,4), (3,4,5)\n",
    "\n",
    "**Expected output shape:** (4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6\n",
    "x = torch.randn(4, 5, 6)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Result: {result}\")\n",
    "assert result.shape == (4,), f\"Expected shape (4,), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: Tensor Permutation and Flattening\n",
    "\n",
    "Create a tensor of shape (2, 3, 4, 5). Permute the dimensions to (4, 2, 5, 3), then flatten the last two dimensions.\n",
    "\n",
    "**Expected output shape:** (4, 2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7\n",
    "x = torch.randn(2, 3, 4, 5)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (4, 2, 15), f\"Expected shape (4, 2, 15), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: Sliding Window\n",
    "\n",
    "Create a 1D tensor of length 20. Create a sliding window view with window size 5 and stride 3.\n",
    "\n",
    "**Expected output shape:** (6, 5) - 6 windows of size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8\n",
    "x = torch.arange(20, dtype=torch.float)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Original tensor: {x}\")\n",
    "\n",
    "# Your solution here (hint: use unfold)\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Result:\\n{result}\")\n",
    "assert result.shape == (6, 5), f\"Expected shape (6, 5), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9: Tensor Gather Operation\n",
    "\n",
    "Create a tensor of shape (3, 5). Create an index tensor to gather elements at positions [1, 3, 0] from each row.\n",
    "\n",
    "**Expected output shape:** (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 9\n",
    "x = torch.randn(3, 5)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Original tensor:\\n{x}\")\n",
    "\n",
    "# Your solution here\n",
    "indices = torch.tensor([[1, 3, 0], [1, 3, 0], [1, 3, 0]])\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Result:\\n{result}\")\n",
    "assert result.shape == (3, 3), f\"Expected shape (3, 3), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10: Tensor Scatter Operation\n",
    "\n",
    "Create a zero tensor of shape (4, 6). Create a source tensor of shape (4, 3) and an index tensor to scatter the source values at specific positions.\n",
    "\n",
    "**Expected behavior:** Place source values at indices [1, 3, 5] for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 10\n",
    "target = torch.zeros(4, 6)\n",
    "source = torch.randn(4, 3)\n",
    "print(f\"Target shape: {target.shape}\")\n",
    "print(f\"Source shape: {source.shape}\")\n",
    "print(f\"Source tensor:\\n{source}\")\n",
    "\n",
    "# Your solution here\n",
    "indices = torch.tensor([[1, 3, 5], [1, 3, 5], [1, 3, 5], [1, 3, 5]])\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Result:\\n{result}\")\n",
    "assert result.shape == (4, 6), f\"Expected shape (4, 6), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11: Complex Slicing with Step\n",
    "\n",
    "Create a tensor of shape (8, 10, 6). Extract elements with:\n",
    "- Every 2nd element from dimension 0, starting from index 1\n",
    "- Elements from index 2 to 8 with step 2 from dimension 1\n",
    "- All elements from dimension 2\n",
    "\n",
    "**Expected output shape:** (4, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 11\n",
    "x = torch.randn(8, 10, 6)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (4, 3, 6), f\"Expected shape (4, 3, 6), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12: Tensor Repeat and Tile\n",
    "\n",
    "Create a tensor of shape (2, 3). Use `repeat` to create a tensor of shape (6, 9) by repeating 3 times along dimension 0 and 3 times along dimension 1.\n",
    "\n",
    "**Expected output shape:** (6, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 12\n",
    "x = torch.randn(2, 3)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Original tensor:\\n{x}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"First few rows of result:\\n{result[:4, :]}\")\n",
    "assert result.shape == (6, 9), f\"Expected shape (6, 9), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13: Tensor Chunking\n",
    "\n",
    "Create a tensor of shape (12, 8). Split it into 3 chunks along dimension 0 and 2 chunks along dimension 1.\n",
    "\n",
    "**Expected output:** List of 6 tensors, each of shape (4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 13\n",
    "x = torch.randn(12, 8)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution (should be a list of tensors)\n",
    "\n",
    "print(f\"Number of chunks: {len(result)}\")\n",
    "print(f\"Shape of each chunk: {[chunk.shape for chunk in result]}\")\n",
    "assert len(result) == 6, f\"Expected 6 chunks, got {len(result)}\"\n",
    "assert all(chunk.shape == (4, 4) for chunk in result), \"Each chunk should have shape (4, 4)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14: Advanced Broadcasting\n",
    "\n",
    "Create two tensors: one of shape (3, 1, 5) and another of shape (1, 4, 1). Multiply them together and verify the result shape.\n",
    "\n",
    "**Expected output shape:** (3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 14\n",
    "x = torch.randn(3, 1, 5)\n",
    "y = torch.randn(1, 4, 1)\n",
    "print(f\"X shape: {x.shape}\")\n",
    "print(f\"Y shape: {y.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (3, 4, 5), f\"Expected shape (3, 4, 5), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15: Tensor Masking and Selection\n",
    "\n",
    "Create a tensor of shape (5, 6). Create a mask where elements in even columns are True. Use `torch.where` to replace masked elements with their negative values.\n",
    "\n",
    "**Expected behavior:** Elements in columns 0, 2, 4 should be negated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 15\n",
    "x = torch.randn(5, 6)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Original tensor:\\n{x}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(f\"Result tensor:\\n{result}\")\n",
    "assert result.shape == (5, 6), f\"Expected shape (5, 6), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16: Tensor Stacking and Concatenation\n",
    "\n",
    "Create 3 tensors of shape (2, 4). Stack them along a new dimension 1, then concatenate the result with itself along dimension 2.\n",
    "\n",
    "**Expected output shape:** (2, 3, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 16\n",
    "x1 = torch.randn(2, 4)\n",
    "x2 = torch.randn(2, 4)\n",
    "x3 = torch.randn(2, 4)\n",
    "print(f\"Individual tensor shapes: {x1.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (2, 3, 8), f\"Expected shape (2, 3, 8), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17: Tensor View vs Reshape\n",
    "\n",
    "Create a tensor of shape (6, 8). Show the difference between `view` and `reshape` by:\n",
    "1. Creating a non-contiguous tensor using transpose\n",
    "2. Trying to use `view` (should fail)\n",
    "3. Using `reshape` successfully\n",
    "\n",
    "**Expected final shape:** (12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 17\n",
    "x = torch.randn(6, 8)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "print(f\"Is contiguous: {x.is_contiguous()}\")\n",
    "\n",
    "# Your solution here\n",
    "# Step 1: Make non-contiguous\n",
    "x_transposed = None  # Replace with your solution\n",
    "\n",
    "# Step 2: Try view (should work with contiguous_view)\n",
    "try:\n",
    "    result_view = None  # Replace with your solution using view\n",
    "    print(\"View succeeded (after making contiguous)\")\n",
    "except:\n",
    "    print(\"View failed on non-contiguous tensor\")\n",
    "    \n",
    "# Step 3: Use reshape\n",
    "result_reshape = None  # Replace with your solution\n",
    "\n",
    "print(f\"Reshape result shape: {result_reshape.shape}\")\n",
    "assert result_reshape.shape == (12, 4), f\"Expected shape (12, 4), got {result_reshape.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18: Advanced Einsum Operation\n",
    "\n",
    "Create two tensors: A of shape (3, 4, 5) and B of shape (5, 6). Use `torch.einsum` to perform matrix multiplication between the last dimension of A and first dimension of B.\n",
    "\n",
    "**Expected output shape:** (3, 4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 18\n",
    "A = torch.randn(3, 4, 5)\n",
    "B = torch.randn(5, 6)\n",
    "print(f\"A shape: {A.shape}\")\n",
    "print(f\"B shape: {B.shape}\")\n",
    "\n",
    "# Your solution here (use einsum)\n",
    "result = torch.einsum()\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (3, 4, 6), f\"Expected shape (3, 4, 6), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 19: Tensor Squeeze and Unsqueeze\n",
    "\n",
    "Create a tensor of shape (1, 5, 1, 3, 1). Remove all singleton dimensions, then add new dimensions at positions 1 and 3.\n",
    "\n",
    "**Expected final shape:** (5, 1, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 19\n",
    "x = torch.randn(1, 5, 1, 3, 1)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Your solution here\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "assert result.shape == (5, 1, 3, 1), f\"Expected shape (5, 1, 3, 1), got {result.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 20: Complex Tensor Manipulation Chain\n",
    "\n",
    "Create a tensor of shape (4, 6, 8). Perform the following operations in sequence:\n",
    "1. Transpose dimensions 0 and 2\n",
    "2. Reshape to (8, 24)\n",
    "3. Split into 3 equal parts along dimension 1\n",
    "4. Stack them along a new dimension 0\n",
    "5. Permute to move the new dimension to position 2\n",
    "\n",
    "**Expected final shape:** (8, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 20\n",
    "x = torch.randn(4, 6, 8)\n",
    "print(f\"Original shape: {x.shape}\")\n",
    "\n",
    "# Your solution here (chain all operations)\n",
    "result = None  # Replace with your solution\n",
    "\n",
    "print(f\"Final shape: {result.shape}\")\n",
    "assert result.shape == (8, 8, 3), f\"Expected shape (8, 8, 3), got {result.shape}\"\n",
    "print(\"\\nCongratulations! You've completed all 20 tensor operation questions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered essential tensor operations including:\n",
    "- Advanced slicing and indexing\n",
    "- Reshaping and permutation\n",
    "- Broadcasting and masking\n",
    "- Gathering and scattering\n",
    "- Stacking and concatenation\n",
    "- Einstein summation (einsum)\n",
    "- Memory layout (contiguous vs non-contiguous)\n",
    "- Complex operation chains\n",
    "\n",
    "These operations are fundamental for:\n",
    "- Data preprocessing\n",
    "- Neural network implementations\n",
    "- Computer vision tasks\n",
    "- Natural language processing\n",
    "- Scientific computing\n",
    "\n",
    "Practice these regularly to build intuition for tensor shapes and operations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
